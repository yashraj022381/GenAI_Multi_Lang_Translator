
import streamlit as st
from transformers import pipeline

# Cache the model loading â€“ loads ONCE, never re-downloads
@st.cache_resource
def load_toxicity_model():
    return pipeline("text-classification", 
                    model="lxyuan/distilbert-base-multilingual-cased-toxic")

st.set_page_config(page_title="SafeGen", page_icon="ğŸ›¡ï¸")

st.title("ğŸ›¡ï¸ SafeGen â€“ AI Output Safety Checker")
st.caption("Built for Indian freelancers & small teams | Free to try | â‚¹399/month later")

text = st.text_area("Paste any AI-generated text (ChatGPT, Gemini, etc.)", height=150)

if st.button("ğŸ” Check Safety", type="primary"):
    with st.spinner("Loading model & analyzing... (first time only)"):
        toxicity = load_toxicity_model()  # This caches it!
        result = toxicity(text)[0]
        score = result['score']
        label = result['label']

        if label == "toxic" and score > 0.7:
            st.error(f"ğŸš¨ High Risk â€“ Toxic/Biased! (Score: {score:.2f})")
            st.write("âš ï¸ Warning: Don't send to clients â€“ could lose trust!")
            st.write("ğŸ’¡ Fix: Add 'Respond politely, factually, and inclusively' to your prompt")
        elif label == "toxic":
            st.warning(f"âš ï¸ Medium Risk (Score: {score:.2f}) â€“ Rephrase for safety")
        else:
            st.success("âœ… Safe & Professional!")
            st.balloons()
st.markdown("---")
st.markdown("Solo Indian founder â€¢ Free for first 100 checks â€¢ [Follow on X](https://x.com/yourhandle)")
